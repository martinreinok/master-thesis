{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Real-Time CNN Susceptibility Artifact Detection\n",
    "Using nnU-Net trained model.\n",
    "Siemens Access-i interface used to connect with the MRI machine."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee1b5b54efb2a8d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1124bbb86ed01cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunetv2/inference/examples.py\n",
    "\"\"\"\n",
    "# %matplotlib inline\n",
    "from skimage import measure\n",
    "import torch\n",
    "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "\"\"\"\n",
    "CNN model defined as global for easy access\n",
    "\"\"\"\n",
    "global cnn_model\n",
    "\n",
    "def prepare_cnn(path_to_model_directory=\"MODEL\", checkpoint_name=\"checkpoint_final.pth\", folds=(4,)):\n",
    "    \"\"\"\n",
    "    :param path_to_model_directory: must have dataset.json & folder containing the fold e.g. fold_4/checkpoint_final.pth\n",
    "    :param checkpoint_name: e.g. checkpoint_final.pth\n",
    "    :param folds: tuple of folds e.g. (4,)\n",
    "    :return: \n",
    "    The model which is prepared to predict\n",
    "    \"\"\"\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    predictor = nnUNetPredictor(\n",
    "        tile_step_size=1,\n",
    "        use_gaussian=True,\n",
    "        use_mirroring=True,\n",
    "        perform_everything_on_gpu=True,\n",
    "        device=torch.device('cuda', 0),\n",
    "        verbose=False,\n",
    "        verbose_preprocessing=False,\n",
    "        allow_tqdm=False\n",
    "    )\n",
    "    predictor.initialize_from_trained_model_folder(path_to_model_directory, checkpoint_name=checkpoint_name, use_folds=folds)\n",
    "    return predictor\n",
    "\n",
    "def image_callback_cnn(image_data):\n",
    "    global cnn_model\n",
    "    if cnn_model is None:\n",
    "        cnn_model = prepare_cnn()\n",
    "    image = cv2.resize(image_data, (512, 512)).astype(np.float32) / 255.0\n",
    "    cnn_input = image.reshape(1, 1, image.shape[0], image.shape[1])\n",
    "    props = {'spacing': (999, 1, 1)}\n",
    "    output = cnn_model.predict_single_npy_array(cnn_input, props, None, None, True)[0]\n",
    "    output_display = (output * 255).astype(np.uint8).reshape(512, 512)\n",
    "    image_display = (image * 255).astype(np.uint8)\n",
    "     \n",
    "def draw_spline(image_data):\n",
    "    spline_points = []\n",
    "    labels = measure.label(image_data > 128)\n",
    "    properties = measure.regionprops(labels)\n",
    "    centers = np.array([prop.centroid for prop in properties])\n",
    "    if len(centers) > 1:\n",
    "        tck, _ = splprep(centers.T, s=0)\n",
    "        spline_points = splev(np.linspace(0, 1, 1000), tck)\n",
    "    return spline_points"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:19:57.237259700Z",
     "start_time": "2024-02-04T20:19:57.215255300Z"
    }
   },
   "id": "18915849a3c3387b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to the Access-i websocket"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11cedf5b161eddfe"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active: True\n",
      "Version: 2.6\n",
      "Register: True, Session: df8bcfe4-38c3-4459-b96d-422eaae6ca46\n",
      "ImageServiceConnection: True\n"
     ]
    }
   ],
   "source": [
    "import siemens_access_library as access_library\n",
    "import asyncio\n",
    "import threading\n",
    "\n",
    "Access = access_library.Access(\"127.0.0.1\")\n",
    "\n",
    "active_check = Access.get_is_active()\n",
    "if active_check is None:\n",
    "    raise SystemExit(\"Server not active\")\n",
    "print(f\"Active: {active_check.value}\")\n",
    "\n",
    "version = Access.get_version()\n",
    "print(f\"Version: {version.value}\")\n",
    "\n",
    "register = Access.register()\n",
    "print(f\"Register: {register.result.success}, Session: {register.sessionId}\")\n",
    "\n",
    "image_format = Access.set_image_format(register.sessionId, \"raw16bit\")\n",
    "\n",
    "\"\"\"\n",
    "Initialize websocket loop for image service\n",
    "\"\"\"\n",
    "def run_websocket_in_thread(session_id, callback_function):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    loop.run_until_complete(Access.connect_websocket(session_id, callback_function))\n",
    "\n",
    "thread = threading.Thread(target=run_websocket_in_thread, args=(register.sessionId, image_callback_cnn))\n",
    "thread.start()\n",
    "# Connect the image service to existing websocket \n",
    "\n",
    "image_service = Access.connect_image_service_to_default_web_socket(register.sessionId)\n",
    "print(f\"ImageServiceConnection: {image_service.result.success}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:20:42.003877500Z",
     "start_time": "2024-02-04T20:20:41.629764400Z"
    }
   },
   "id": "2d9936c7104928"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
